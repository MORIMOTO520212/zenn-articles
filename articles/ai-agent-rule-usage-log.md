---
title: "CLAUDE.mdは本当に読まれているのか？ ルールの使用率を測定してプロンプト肥大化を防ぐ"
emoji: "📊"
type: "tech"
topics: ["AI", "Claude", "開発生産性", "ドキュメント", "エンジニアリング"]
published: false
---

## この記事で分かること

- AIエージェントがルールを読んでいるか可視化する方法
- 使用率測定で冗長なルールを半減させた実例
- 2ヶ月の運用で分かった「本当に効くルール」

対象読者：Claude CodeやAIエージェントをプロジェクトで活用しているエンジニア

---

## なぜこの仕組みが必要だったのか

AIエージェント（Claude Codeなど）を使った開発では、プロジェクト固有のルールをドキュメント化して参照させるのが一般的です。ディレクトリ構成、コミットメッセージの規約、コーディングスタイルなどを `AGENTS.md` や `CLAUDE.md` に記述し、エージェントに読ませます。

しかし、次のような課題がありました。

- **ルールが本当に参照されているか分からない**：エージェントがルールを読んでいるのか、単に既存コードから推測しているのか判別できない
- **ルールが肥大化する**：「念のため」で追加したルールが蓄積し、本当に必要なルールが埋もれる
- **改善のPDCAが回せない**：どのルールが有効で、どれが不要かのデータがない

これらの課題を解決するため、**ルール参照の記録を自動化する仕組み**を導入しました。

---

## RULES_USAGE_LOGの仕組み

### 基本構造

プロジェクトルートに `RULES_USAGE_LOG.md` を配置し、AIエージェントが実装判断でルールを参照した場合、以下のフォーマットでログを記録させます。

```yaml
- date: 2026-02-24
  file: AGENTS.md
  rule: 単体テストのルール
  reason: useParkingSelectRouter.ts のテスト作成時に、テストファイルを `src/features/parking/composables/__test__/useParkingSelectRouter.spec.ts` に配置する判断根拠として使用
```

各フィールドの意味：

| フィールド | 説明 |
|-----------|------|
| `date` | ルールを参照した日付（YYYY-MM-DD形式） |
| `file` | 参照したルールファイル（`AGENTS.md` または `CLAUDE.md`） |
| `rule` | 参照した具体的なルールセクション名 |
| `reason` | どの実装判断でそのルールを根拠としたか |

実際のログはこのように記録されます：

![実際のRULES_USAGE_LOG.mdの記録例](https://storage.googleapis.com/zenn-user-upload/e2934024c51e-20260224.png)
*VSCodeのdiffビューで見たログエントリ*

### ルールファイルへの組み込み

`AGENTS.md` や `CLAUDE.md` の冒頭に、以下のような指示を追加します。

```markdown
## Rule Evaluation Policy

AIが実装判断においてルールファイル（`AGENTS.md` / `CLAUDE.md`）を「判断根拠として利用したか」を定量的に評価する。
そのため、AIは実装過程でルールが実装判断に寄与した場合、`./RULES_USAGE_LOG.md`にログを必ず記録すること。

### When a Rule Should Be Counted as "Used"

以下の**すべて**を満たす場合のみ、ルールを「使用した」とみなす。

1. **判断前の参照**: その判断を行う**前に**、ルールファイルを開いて該当ルールを読んだ
2. **明示的な根拠**: 読んだルールが、その判断の直接的な根拠となった
3. **代替案の存在**: そのルールがなければ、異なる実装を選択していた可能性がある
```

---

## カウント基準の厳密な設計

この仕組みの核心は、**「ルールを使用した」の定義を厳密にすること**です。曖昧な基準では、エージェントが事後的に「使用した」と記録してしまい、データの価値が損なわれます。

### ❌ カウントしないケース

以下のようなケースは「未使用」として扱います。

- **既存コードを見て同じパターンで実装した → 後でルールに合致していることに気づいた**
  - 実装判断の根拠は既存コードであり、ルールではない
- **実装完了後の振り返りで、ルールファイルを初めて確認した**
  - タイミングが遅い。判断には寄与していない
- **一般的なベストプラクティスに従った（ルールファイルを見ずに判断）**
  - ルールがなくても同じ判断をしていた
- **ルールを読んだが、すでに決めていた方針を追認しただけ**
  - ルールが判断に影響を与えていない

### ✅ カウントするケース

逆に、以下のケースは「使用した」として記録します。

- **ディレクトリ配置に迷った → AGENTS.mdの構成ルールを確認 → それに従って配置決定**
- **コミットメッセージを書く前に → CLAUDE.mdを開いて絵文字ルールを確認 → それに従って作成**
- **命名に迷った → ルールファイルで命名規則を確認 → それに従って命名**

実際の例：

![テストファイルの配置を判断する際にルールを参照](https://storage.googleapis.com/zenn-user-upload/966a9ad442f8-20260224.png)
*テストパターンを確認する際、AGENTS.mdのルールに従ってテストファイルを作成する判断をしている*

### 記録時の確認プロセス

エージェントには、記録前に以下の3つの質問に答えさせます。

1. **タイミング**: 判断を下す前にルールファイルを開きましたか？
2. **参照**: 該当する具体的なルールセクションを読みましたか？
3. **影響**: そのルールを読まなければ、違う判断をしていましたか？

**1つでも「いいえ」なら記録しない**というルールを徹底します。

---

## 実運用での効果

実際にこの仕組みを運用すると、AIエージェントがルールを参照する様子を可視化できます。

![Claude CodeがAGENTS.mdのルールを参照している様子](https://storage.googleapis.com/zenn-user-upload/3462c569ef98-20260224.png)
*テスト作成時に、AGENTS.mdの「単体テストのルール」を確認している場面*

### 実際の記録例

実プロジェクトで2ヶ月間運用した結果、以下のようなログが蓄積されました。

```yaml
- date: 2026-02-24
  file: AGENTS.md
  rule: 単体テストのルール
  reason: useParkingSelectRouter.ts のテスト作成時に、テストファイルを `__test__/ファイル名.spec.ts` の形式で配置する判断根拠として使用

- date: 2026-02-21
  file: AGENTS.md
  rule: 単体テストのルール
  reason: useFormatVehicleNumber.ts のテスト作成時に、テストファイル配置場所を決定する判断根拠として使用

- date: 2026-02-17
  file: CLAUDE.md
  rule: コミットルール
  reason: バグ修正のコミットメッセージ作成時に、絵文字(🐛 fix:)の選択と日本語記述の判断根拠として使用

- date: 2026-02-17
  file: AGENTS.md
  rule: ディレクトリ構成（Package by Feature）
  reason: 駐車予定色フィールド追加時に、features/monthly/配下の構造に従って編集対象ファイルを特定する判断根拠として使用
```

### 得られた知見

#### 1. 頻繁に参照されるルール

**最多参照**：「単体テストのルール」（8回）
- テストファイルの配置場所は実装者が毎回迷うポイント
- ルールが明確に記述されていることで、判断の一貫性が保たれた

**次点**：「コミットルール」（6回）
- 絵文字の選択や日本語記述のルールは、毎回確認が必要
- エージェントが自信を持って判断できるポイント

#### 2. 参照されなかったルール

一方で、以下のようなルールは2ヶ月間一度も参照されませんでした。

- **ドメイン用語の定義**
  - 既存コードから文脈で理解されていた
  - 新規用語が追加されるタイミングでのみ必要
- **技術スタックのリスト**
  - package.jsonやimport文から推測可能
  - ドキュメントとしての価値は低い

#### 3. ルール改善のサイクル

このログを元に、以下のようなルール改善を実施しました。

1. **参照頻度の高いルールを上部に移動**：エージェントが素早くアクセスできるよう配置を最適化
2. **未参照ルールの削減**：2ヶ月間参照されなかったルールを別ファイル（`REFERENCE.md`）に分離
3. **reason フィールドの分析**：同じルールを参照しているのに異なる解釈がある場合、ルールの記述を明確化

---

## 技術的な工夫

### 作業完了時の自動チェック

エージェントが「タスク完了」と判断したタイミングで、自動的に以下のチェックを実行させます。

```markdown
## 作業終了時（タスク完了時など）には、Rule Evaluation Policyに基づいて必ず以下のチェックを実行すること

**実行タイミング:**
- 実装・修正が完了した時点（ユーザーの動作確認を待たずに実行）
- バグ修正が完了した時点
- 一つの機能追加が実装完了した時点

**チェック項目:**
1. **ルール使用の振り返り**
   - 今回の作業でAGENTS.md / CLAUDE.mdのルールを判断根拠として使用したか？
   - 使用した場合、RULES_USAGE_LOG.mdに記録したか？
```

このチェックフローにより、記録漏れを防ぎます。

実際の動作例：

![ルール参照後、RULES_USAGE_LOG.mdへの記録を宣言](https://storage.googleapis.com/zenn-user-upload/68a75e419766-20260224.png)
*ルールを参照した後、ログに記録することを宣言*

![Rule Evaluation Policyに従ったチェック完了の報告](https://storage.googleapis.com/zenn-user-upload/544aadaa1120-20260224.png)
*作業完了時に自動的にチェックが実行され、報告される*

### 最新のログを上部に配置

ログは**降順（最新が上）**で記録するルールにしています。これにより、最近の傾向を素早く把握できます。

```yaml
## Logs

- date: 2026-02-24  # 最新
  file: AGENTS.md
  rule: 単体テストのルール
  reason: ...

- date: 2026-02-21  # 過去
  file: AGENTS.md
  rule: 単体テストのルール
  reason: ...
```

---

## 導入のステップ

この仕組みをあなたのプロジェクトに導入する場合、以下のステップで進めることを推奨します。

### Step 1: RULES_USAGE_LOG.md の作成

プロジェクトルートに以下の内容でファイルを作成します。

```markdown
# Rules Usage Log

## Description

### Log Format

以下のフォーマットで記録してください。

- date: 日付YYYY-MM-dd
- file: 参照したルールファイル(AGENTS.md | CLAUDE.md)
- rule: 対象のルールセクション
- reason: 当該ルールを判断根拠とした理由

### Example

以下はログの例です。
最新のものが一番上に来るようにしてください。

- date: 2026-01-24
  file: AGENTS.md
  rule: ディレクトリ構成ルール
  reason: 新規API追加時の配置判断

## Logs

(ここにログが蓄積されます)
```

### Step 2: ルールファイルへの追記

既存の `AGENTS.md` や `CLAUDE.md` の冒頭に、Rule Evaluation Policy を追加します。（上述の「ルールファイルへの組み込み」を参照）

### Step 3: 1週間の試験運用

まずは1週間運用してログを観察します。以下を確認します。

- エージェントが正しくログを記録しているか
- カウント基準が厳密に守られているか（事後的な記録がないか）
- 記録されたログが判断の根拠として妥当か

### Step 4: 定期的な振り返り

1ヶ月〜2ヶ月ごとにログを分析し、以下のアクションを取ります。

- **高頻度ルール**：ルールの記述をより明確にする、よくあるケースの例を追加する
- **未参照ルール**：本当に必要か再検討し、不要なら削除または別ファイルに移動
- **reason フィールドの傾向分析**：同じルールでも異なる解釈がある場合、ルールを改善する

---

## この仕組みの限界と今後の展望

### 現状の限界

この仕組みにも限界があります。

1. **エージェントの自己申告に依存**
   - 記録するかどうかはエージェントの判断に委ねられる
   - 厳密な検証には、プロンプトログの解析が必要
2. **短期間のログでは傾向が見えにくい**
   - 最低でも1ヶ月以上の運用が必要
   - プロジェクトの開発フェーズによって参照頻度が変動する
3. **ルールの粒度調整が難しい**
   - 粒度が細かすぎるとログが煩雑になる
   - 粒度が粗いと改善ポイントが見えにくい

### 今後の展望

以下のような拡張を検討しています。

- **自動集計ダッシュボード**：ログをパースして、ルールごとの参照回数をグラフ化
- **未参照ルールのアラート**：1ヶ月間参照されなかったルールを自動検出
- **ルール間の関連性分析**：同時に参照されるルールのパターンを可視化

---

## まとめ

AIエージェントに対するルールドキュメントは、「書いたら終わり」ではありません。本当に参照されているか、実装判断に寄与しているかを定量的に測定することで、ルールの品質を継続的に改善できます。

RULES_USAGE_LOGの仕組みは以下の3つのポイントで構成されています。

1. **厳密なカウント基準**：判断前の参照、明示的な根拠、代替案の存在
2. **自動記録の習慣化**：作業完了時の自動チェックフロー
3. **継続的な改善サイクル**：ログの分析とルールの最適化

この仕組みを導入することで、ルールの肥大化を防ぎ、本当に価値のあるルールだけを磨き上げることができます。AIエージェントとの協働をより効果的にするために、ぜひ試してみてください。

---

## 参考リンク

- [Claude Code公式ドキュメント](https://docs.claude.com/en/docs/claude-code)
- [プロジェクト構成のベストプラクティス](https://nuxt.com/docs/guide/directory-structure)
